---
title: "Abstract Acquisition Analyses"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(jtools)
library(stats)
library(Hmisc)
library(ggplot2)
library(olsrr)
library(corrplot)
library(renv)
library(papaja)
library(dplyr)
library(magrittr)
library(readr)
library(apaTables)
library(tidyr)

```

#Results

```{r load data and format, include = FALSE}
#read in data
AoA <- read_csv("Dale_ORourke_AoA.csv")
Concrete <- read_csv("Brysbaert_Kuperman_Concrete.csv")
Valence <- read_csv("Warriner_Valence.csv")

#remove all columns but word and rating
AoA_test <- AoA %>% 
  select(Word, AoAtestbased)

AoA_rate <- AoA %>% 
  select(Word, AoArating)

Concrete <- Concrete %>% 
  select(Word, Conc.M)

Valence <- Valence %>% 
  select(Word, V.Mean.Sum)

#take min values for unique items in AoA test based norms
low_AoA_test <- aggregate(AoAtestbased ~ Word, AoA_test, min)
max_AoA_test <- aggregate(AoAtestbased ~ Word, AoA_test, max)
AoA_rate_unique <- unique(AoA_rate)
colnames(low_AoA_test) <- c("Word", "AoA_test_min")
colnames(max_AoA_test) <- c("Word", "AoA_test_max")

#merge unique AoA test-based min and max values with concreteness and AoA ratings to see availability
AoA_all <- merge(low_AoA_test, max_AoA_test)

#merge unique AoA test-based min and max values with concreteness to see availability
AoA_Conc <- merge(AoA_all, Concrete, all.x = TRUE)
AoA_Conc_narm <- na.omit(AoA_Conc)

#merge unique AoA test-based min and max values with AoA ratings-based to see availability
AoA_Rate <- merge(AoA_all, AoA_rate_unique, all.x = TRUE)
AoA_Rate_narm <- na.omit(AoA_Rate)

#merge unique AoA test-based min and max values with valence to see availability
AoA_Val <- merge(AoA_all, Valence, all.x = TRUE)
AoA_Val_narm <- na.omit(AoA_Val)

#merge unique AoA test-based min and max values with concreteness and valence to see availability
AoA_regression <- merge(AoA_all, Concrete, all.x = TRUE)
AoA_regression <- merge(AoA_regression, Valence, all.x = TRUE)
AoA_regression_narm <- na.omit(AoA_regression)
sample <- nrow(AoA_regression_narm)

#look correlations between lowest AoA meaning test-based and concreteness and valence
AoAtestmin_Concrete_corr <- cor.test(AoA_Conc_narm$AoA_test_min, AoA_Conc_narm$Conc.M)
AoAtestmin_AoArate_corr <- cor.test(AoA_Rate_narm$AoA_test_min, AoA_Rate_narm$AoArating)
AoAtestmin_Val_corr <- cor.test(AoA_Val_narm$AoA_test_min, AoA_Val_narm$V.Mean.Sum)

print(AoAtestmin_Concrete_corr)
print(AoAtestmin_Val_corr)

#Create table of descriptives and correlations
save <- apa.cor.table(AoA_regression_narm)
descriptives <- as.data.frame(save$table.body)
descriptives <- descriptives %>% 
  filter(M > 0, Variable != "2. AoA_test_max") %>% 
  mutate(Variable = replace(Variable, which(Variable == "1. AoA_test_min"), "1. Age of Acquisition")) %>% 
  mutate(Variable = replace(Variable, which(Variable == "3. Conc.M"), "2. Concreteness")) %>%
  mutate(Variable = replace(Variable, which(Variable == "4. V.Mean.Sum"), "3. Valence"))
```

```{r Table 1}
papaja::apa_table(descriptives, caption = "Mean, Standard Deviations, & Correlations (N = 11,535)", note = "Making a table. ** = p < .01", escape = TRUE)
```

We combined data from Dale & O'Rourke, Brysbaert, and Warriner. It was super fun. In total we have `r printnum(sample)` observations.

```{r}
#Reduce dataframe to only abstract words (items with concreteness rating less than 3)
AoA_abstract <- AoA_regression_narm %>%
  filter(Conc.M < 3)

#Load in associates data
Associates <- read_csv("First_assoc_data.csv")

#Merge data
AoA_abstract_assoc <- merge(AoA_abstract, Associates, by = "Word", all.x = TRUE)
AoA_abstract_assoc <- AoA_abstract_assoc %>% 
  select(Word, AoA_test_min, AoA_test_max, Conc.M, V.Mean.Sum, Assoc, AoA_Assoc, Conc_Assoc, Valence_Assoc)

#Run polynomial regression using valence to predict test-based AoA with second-order (quadratic) term
fit_abstract2 <- lm(AoA_test_min ~ poly(V.Mean.Sum,2), data = AoA_abstract)
summary(fit_abstract2)

#see model summary with b coefficients
summ(fit_abstract2, digits = 3)

#see model summary with beta coefficients 
summ(fit_abstract2, scale = TRUE, transform.response = TRUE, digits = 3)

##Check part and partial correlations
ols_correlations(fit_abstract2)

#Plot quadratic relationship
Valplot <-ggplot(AoA_abstract, aes(x = V.Mean.Sum, y=AoA_test_min)) + geom_point(color = "grey", size = .5, alpha = .5) + stat_smooth(se = T, method = 'lm', formula = y~poly(x,2), color = "red") + theme_classic() + labs(x = "Valence", y = "Test-based AoA") + ggtitle("Abstract words") + theme(plot.title = element_text(hjust = 0.5))

#View plot
print(Valplot)

#Save png of plot to working directory
#ggsave("Valplot.png", width = 5, height = 3)

```

```{r Testing Predictiveness of Adult Associate Valence}

Associate_Valence <- AoA_abstract_assoc %>% 
  select(Word, AoA_test_min, Assoc, Valence_Assoc) %>% 
  drop_na()

#Run regression to predict Associates structure valence
fit_abstract3 <- lm(AoA_test_min ~ poly(Valence_Assoc,2), data = Associate_Valence)
summary(fit_abstract3)

#Plot quadratic relationship
ValAssocplot <-ggplot(Associate_Valence, aes(x = Valence_Assoc, y=AoA_test_min)) + geom_point(color = "grey", size = .5, alpha = .5) + stat_smooth(se = T, method = 'lm', formula = y~poly(x,2), color = "red") + theme_classic() + labs(x = "Valence of Associate", y = "Test-based AoA") + ggtitle("Abstract words") + theme(plot.title = element_text(hjust = 0.5))

#View plot
print(ValAssocplot)
```

